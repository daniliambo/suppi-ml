{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import DateOffset\n",
    "from utils.reader import ReadData\n",
    "import pandas as pd\n",
    "\n",
    "def train_test_split(df):\n",
    "\n",
    "    def set_datetime(df):\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.set_index('date', drop=True, inplace=False)\n",
    "        df.sort_index(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def get_split(df: pd.DataFrame):\n",
    "        offset = df.index[-1] - DateOffset(weeks=1)\n",
    "        df_train = df[df.index < offset]\n",
    "        df_test = df[df.index >= offset]\n",
    "        df_train.reset_index(inplace=True)\n",
    "        df_test.reset_index(inplace=True)\n",
    "        return df_train, df_test\n",
    "\n",
    "    df = set_datetime(df)\n",
    "    df_train, df_test = get_split(df)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "def set_target(df):\n",
    "    TARGET = 'TARGET'\n",
    "    qp, qr = 'quantity_of_paid', 'quantity_of_return',\n",
    "    df[TARGET] = df[qp] - df[qr]\n",
    "    df.drop([qp, qr], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_and_preprocess(file):\n",
    "    # data, feature, meta\n",
    "    reader = ReadData()\n",
    "    df = reader.read(file)\n",
    "    if file == 'data':\n",
    "        df = set_target(df)\n",
    "    df_train, df_test = train_test_split(df)\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "df_data_train, df_data_test = load_and_preprocess('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 1 of 6) Processing drop_data, total=   0.0s\n",
      "[Pipeline] . (step 2 of 6) Processing drop_na_base_data, total=   0.0s\n",
      "[Pipeline] . (step 3 of 6) Processing drop_fill_na_data, total=   0.1s\n",
      "[Pipeline]  (step 4 of 6) Processing drop_non_informative_data, total=   0.0s\n",
      "[Pipeline]  (step 5 of 6) Processing join_non_informative_data, total=   0.0s\n",
      "[Pipeline] . (step 6 of 6) Processing group_by_day_data, total=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(mode_, inplace=True)\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(X.groupby([self.col_group_by_1, self.col_group_by_2])[\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(X.groupby(self.col_group_by_1)[col].transform(\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(pd.Series.mean(X[col]), inplace=True)\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(X.groupby([self.col_group_by_1, self.col_group_by_2])[\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(X.groupby(self.col_group_by_1)[col].transform(\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(pd.Series.mean(X[col]), inplace=True)\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(cols_with_zeros +\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['sum_' + '_'.join(numeric_columns)] = X.loc[:,\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['accruals'] = X[ao] + X[ar]\n",
      "/Users/dev.daniil.bakushkin/Desktop/suppi/ml/app/pipeline/step_0/custom_transformers.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(columns_to_drop, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from pipeline.step_0.build_pipeline import load_and_preprocess as load_and_preprocess_step_0\n",
    "df_train = load_and_preprocess_step_0(df_data_train, inference=False)\n",
    "df_test = load_and_preprocess_step_0(df_data_test, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing keep_feature, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev.daniil.bakushkin/miniconda3/envs/shad/lib/python3.11/site-packages/sklearn/utils/extmath.py:1051: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/dev.daniil.bakushkin/miniconda3/envs/shad/lib/python3.11/site-packages/sklearn/utils/extmath.py:1056: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/dev.daniil.bakushkin/miniconda3/envs/shad/lib/python3.11/site-packages/sklearn/utils/extmath.py:1076: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 2 of 2) Processing knn, total=  33.2s\n"
     ]
    }
   ],
   "source": [
    "# from pipeline.step_1.build_pipeline import load_and_preprocess as load_and_preprocess_step_1\n",
    "\n",
    "from pipeline.step_1 import build_pipeline\n",
    "import imp\n",
    "imp.reload(build_pipeline)\n",
    "\n",
    "load_and_preprocess_step_1 = build_pipeline.load_and_preprocess\n",
    "df_feature_train, df_feature_test = load_and_preprocess('feature')\n",
    "# df_feature_train = df_feature_train.loc[:100, :]\n",
    "# df_feature_test = df_feature_test.loc[:100, :]\n",
    "\n",
    "df_feature_train = load_and_preprocess_step_1(\n",
    "    df_feature_train, inference=False)\n",
    "df__feature_test = load_and_preprocess_step_1(df_feature_test, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 date\n",
      "499 offer_id\n",
      "1 shop_id\n",
      "510 num_actions\n",
      "2860 position_category\n",
      "1 price_index\n",
      "1 external_index_data_minimal_price\n",
      "1 external_index_data_price_index_value\n",
      "1 self_marketplaces_index_data_minimal_price\n",
      "1 self_marketplaces_index_data_price_index_value\n",
      "1 marketing_seller_price\n",
      "234 marketing_price\n",
      "1 conv_tocart\n",
      "1386 conv_tocart_pdp\n",
      "1269 hits_tocart\n",
      "1 hits_tocart_pdp\n",
      "1 hits_view_search\n"
     ]
    }
   ],
   "source": [
    "for col in df_feature_train.columns:\n",
    "  print(df_feature_train[col].nunique(), col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 date\n",
      "499 offer_id\n",
      "1 shop_id\n",
      "510 num_actions\n",
      "2860 position_category\n",
      "1 price_index\n",
      "1 external_index_data_minimal_price\n",
      "1 external_index_data_price_index_value\n",
      "1 self_marketplaces_index_data_minimal_price\n",
      "1 self_marketplaces_index_data_price_index_value\n",
      "1 marketing_seller_price\n",
      "234 marketing_price\n",
      "1 conv_tocart\n",
      "1386 conv_tocart_pdp\n",
      "1269 hits_tocart\n",
      "1 hits_tocart_pdp\n",
      "1 hits_view_search\n"
     ]
    }
   ],
   "source": [
    "for col in df_feature_train.columns:\n",
    "  print(df_feature_train[col].nunique(), col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
